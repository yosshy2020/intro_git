{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnntrain.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwxOYd9XCn7CK5EOy9ySiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yosshy2020/intro_git/blob/master/cnntrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TAlt9kwHGT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfec62bb-f6fd-4c08-fcb1-f21571a0933f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvpmIH990z49",
        "outputId": "c6a1e83a-51f5-4447-c2a1-f53b19f29e94"
      },
      "source": [
        "!pip install hyperas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.7.1)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.6.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (1.0.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (22.0.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (53.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov6zXexL2LcU"
      },
      "source": [
        "from hyperopt import hp\n",
        "from hyperopt import Trials, tpe\n",
        "from hyperas import optim \n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inusc2kpLBvt"
      },
      "source": [
        "def prepare_data():\n",
        "  \n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  from sklearn.model_selection import KFold\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import Dense, Activation ,Dropout\n",
        "\n",
        "  train = pd.read_csv('/content/drive/MyDrive/biginners/train.csv')\n",
        "  test = pd.read_csv('/content/drive/MyDrive/biginners/test.csv')\n",
        "\n",
        "  all_data = pd.concat((train.loc[:,'age':'native-country'],\n",
        "                      test.loc[:,'age':'native-country']))\n",
        "  \n",
        "  all_data_df =  pd.get_dummies(all_data, columns=[\"workclass\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"education\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"marital-status\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"occupation\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"relationship\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"race\"])\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"sex\"], drop_first=True)\n",
        "  all_data_df =  pd.get_dummies(all_data_df, columns=[\"native-country\"])\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  all_data_df[['age', 'fnlwgt', 'education-num']] = scaler.fit_transform(all_data_df[['age', 'fnlwgt', 'education-num']])\n",
        "\n",
        "  train_X = all_data_df[:train.shape[0]]\n",
        "  test_X = all_data_df[train.shape[0]:]\n",
        "  train_Y= train.Y\n",
        "\n",
        "  kf = KFold(n_splits=4, shuffle= True, random_state=123)\n",
        "  tr_idx, va_idx = list(kf.split(train_X))[0] \n",
        "\n",
        "  tr_x, va_x = train_X.iloc[tr_idx], train_X.iloc[va_idx]\n",
        "  tr_y, va_y = train_Y.iloc[tr_idx], train_Y.iloc[va_idx]\n",
        "\n",
        "  return tr_x, tr_y, va_x, va_y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHDTUJdsd-VC"
      },
      "source": [
        "def create_model(tr_x, tr_y):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(\n",
        "      {{choice([500, 784])}},\n",
        "      input_dim=tr_x.shape[1],\n",
        "      activation='relu'\n",
        "       ))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  if {{choice(['none', 'one', 'two'])}} == 'none':\n",
        "    pass\n",
        "\n",
        "  elif {{choice(['none', 'one', 'two'])}} == 'one':\n",
        "    model.add(Dense(\n",
        "      {{choice([100, 200])}},\n",
        "      activation='relu'\n",
        "      ))\n",
        "  \n",
        "  elif {{choice(['none', 'one', 'two'])}} == 'two':\n",
        "    model.add(Dense(\n",
        "      {{choice([100, 200])}},\n",
        "      activation='relu'\n",
        "      ))\n",
        "    model.add(Dense(\n",
        "      {{choice([25, 50])}},\n",
        "      activation='relu'\n",
        "      ))\n",
        "    \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer={{choice(['adam', 'rmsprop'])}},\n",
        "    metrics=['accuracy'])\n",
        "  \n",
        "  epoch =10\n",
        "  batch_size =100\n",
        "\n",
        "  result = model.fit(tr_x, tr_y,\n",
        "                   epochs=epoch,\n",
        "                   batch_size=batch_size,\n",
        "                   validation_data=(va_x, va_y),\n",
        "                   verbose=0)\n",
        "  \n",
        "  validation_acc =np.amax(result.history['val_accuracy'])\n",
        "  print('Accuracy in search', validation_acc)\n",
        "\n",
        "  return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdxvDnAQDfS6",
        "outputId": "1ee4c254-4166-4d05-e763-b51cfecb5b49"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                          data=prepare_data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=20,\n",
        "                                          notebook_name = '/drive/MyDrive/Colab Notebooks/cnntrain',\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import hp\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.utils import to_categorical\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import KFold\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.preprocessing import MinMaxScaler\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.layers import Dense, Activation, Dropout\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dense': hp.choice('Dense', [500, 784]),\n",
            "        'Dense_1': hp.choice('Dense_1', ['none', 'one', 'two']),\n",
            "        'Dense_2': hp.choice('Dense_2', ['none', 'one', 'two']),\n",
            "        'Dense_3': hp.choice('Dense_3', [100, 200]),\n",
            "        'Dense_4': hp.choice('Dense_4', ['none', 'one', 'two']),\n",
            "        'Dense_5': hp.choice('Dense_5', [100, 200]),\n",
            "        'Dense_6': hp.choice('Dense_6', [25, 50]),\n",
            "        'optimizer': hp.choice('optimizer', ['adam', 'rmsprop']),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: \n",
            "   3: import numpy as np\n",
            "   4: import pandas as pd\n",
            "   5: from tensorflow.keras.utils import to_categorical\n",
            "   6: from sklearn.model_selection import KFold\n",
            "   7: from sklearn.preprocessing import MinMaxScaler\n",
            "   8: from tensorflow.keras.models import Sequential\n",
            "   9: from tensorflow.keras.layers import Dense, Activation ,Dropout\n",
            "  10: \n",
            "  11: train = pd.read_csv('/content/drive/MyDrive/biginners/train.csv')\n",
            "  12: test = pd.read_csv('/content/drive/MyDrive/biginners/test.csv')\n",
            "  13: \n",
            "  14: all_data = pd.concat((train.loc[:,'age':'native-country'],\n",
            "  15:                     test.loc[:,'age':'native-country']))\n",
            "  16: \n",
            "  17: all_data_df =  pd.get_dummies(all_data, columns=[\"workclass\"])\n",
            "  18: all_data_df =  pd.get_dummies(all_data_df, columns=[\"education\"])\n",
            "  19: all_data_df =  pd.get_dummies(all_data_df, columns=[\"marital-status\"])\n",
            "  20: all_data_df =  pd.get_dummies(all_data_df, columns=[\"occupation\"])\n",
            "  21: all_data_df =  pd.get_dummies(all_data_df, columns=[\"relationship\"])\n",
            "  22: all_data_df =  pd.get_dummies(all_data_df, columns=[\"race\"])\n",
            "  23: all_data_df =  pd.get_dummies(all_data_df, columns=[\"sex\"], drop_first=True)\n",
            "  24: all_data_df =  pd.get_dummies(all_data_df, columns=[\"native-country\"])\n",
            "  25: \n",
            "  26: scaler = MinMaxScaler()\n",
            "  27: all_data_df[['age', 'fnlwgt', 'education-num']] = scaler.fit_transform(all_data_df[['age', 'fnlwgt', 'education-num']])\n",
            "  28: \n",
            "  29: train_X = all_data_df[:train.shape[0]]\n",
            "  30: test_X = all_data_df[train.shape[0]:]\n",
            "  31: train_Y= train.Y\n",
            "  32: \n",
            "  33: kf = KFold(n_splits=4, shuffle= True, random_state=123)\n",
            "  34: tr_idx, va_idx = list(kf.split(train_X))[0] \n",
            "  35: \n",
            "  36: tr_x, va_x = train_X.iloc[tr_idx], train_X.iloc[va_idx]\n",
            "  37: tr_y, va_y = train_Y.iloc[tr_idx], train_Y.iloc[va_idx]\n",
            "  38: \n",
            "  39: \n",
            "  40: \n",
            "  41: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:   model = Sequential()\n",
            "   4: \n",
            "   5:   model.add(Dense(\n",
            "   6:       space['Dense'],\n",
            "   7:       input_dim=tr_x.shape[1],\n",
            "   8:       activation='relu'\n",
            "   9:        ))\n",
            "  10:   model.add(Dropout(0.4))\n",
            "  11: \n",
            "  12:   if space['Dense_1'] == 'none':\n",
            "  13:     pass\n",
            "  14: \n",
            "  15:   elif space['Dense_2'] == 'one':\n",
            "  16:     model.add(Dense(\n",
            "  17:       space['Dense_3'],\n",
            "  18:       activation='relu'\n",
            "  19:       ))\n",
            "  20:   \n",
            "  21:   elif space['Dense_4'] == 'two':\n",
            "  22:     model.add(Dense(\n",
            "  23:       space['Dense_5'],\n",
            "  24:       activation='relu'\n",
            "  25:       ))\n",
            "  26:     model.add(Dense(\n",
            "  27:       space['Dense_6'],\n",
            "  28:       activation='relu'\n",
            "  29:       ))\n",
            "  30:     \n",
            "  31:   model.add(Dense(1, activation='sigmoid'))\n",
            "  32: \n",
            "  33:   model.compile(\n",
            "  34:     loss='mean_squared_error',\n",
            "  35:     optimizer=space['optimizer'],\n",
            "  36:     metrics=['accuracy'])\n",
            "  37:   \n",
            "  38:   epoch =10\n",
            "  39:   batch_size =100\n",
            "  40: \n",
            "  41:   result = model.fit(tr_x, tr_y,\n",
            "  42:                    epochs=epoch,\n",
            "  43:                    batch_size=batch_size,\n",
            "  44:                    validation_data=(va_x, va_y),\n",
            "  45:                    verbose=0)\n",
            "  46:   \n",
            "  47:   validation_acc =np.amax(result.history['val_accuracy'])\n",
            "  48:   print('Accuracy in search', validation_acc)\n",
            "  49: \n",
            "  50:   return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
            "  51: \n",
            "Accuracy in search\n",
            "0.8430252075195312\n",
            "Accuracy in search\n",
            "0.8420168161392212\n",
            "Accuracy in search\n",
            "0.8447058796882629\n",
            "Accuracy in search\n",
            "0.8413445353507996\n",
            "Accuracy in search\n",
            "0.8440335988998413\n",
            "Accuracy in search\n",
            "0.8436974883079529\n",
            "Accuracy in search\n",
            "0.8389915823936462\n",
            "Accuracy in search\n",
            "0.8410084247589111\n",
            "Accuracy in search\n",
            "0.8440335988998413\n",
            "Accuracy in search\n",
            "0.8423529267311096\n",
            "Accuracy in search\n",
            "0.8406722545623779\n",
            "Accuracy in search\n",
            "0.8443697690963745\n",
            "Accuracy in search\n",
            "0.8433613181114197\n",
            "Accuracy in search\n",
            "0.8433613181114197\n",
            "Accuracy in search\n",
            "0.841680645942688\n",
            "Accuracy in search\n",
            "0.841680645942688\n",
            "Accuracy in search\n",
            "0.8420168161392212\n",
            "Accuracy in search\n",
            "0.8453781604766846\n",
            "Accuracy in search\n",
            "0.8430252075195312\n",
            "Accuracy in search\n",
            "0.8420168161392212\n",
            "100%|██████████| 20/20 [01:51<00:00,  5.58s/it, best loss: -0.8453781604766846]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQhGSCirkxYZ",
        "outputId": "826a4959-ce96-4d1e-8f7f-dc9a349166cf"
      },
      "source": [
        "print(best_model.summary())\n",
        "\n",
        "print(best_run)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_46 (Dense)             (None, 500)               28000     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 28,501\n",
            "Trainable params: 28,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "{'Dense': 0, 'Dense_1': 1, 'Dense_2': 2, 'Dense_3': 1, 'Dense_4': 0, 'Dense_5': 1, 'Dense_6': 0, 'optimizer': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okJ_piVSm6kE",
        "outputId": "64f208c7-b262-444f-a9c8-d1debca71a11"
      },
      "source": [
        "_, _, va_x, va_y = prepare_data()\n",
        "val_loss, val_acc = best_model.evaluate(va_x, va_y)\n",
        "print(\"val_loss: \", val_loss)\n",
        "print(\"val_acc\", val_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 0s 993us/step - loss: 0.1117 - accuracy: 0.8454\n",
            "val_loss:  0.11169950664043427\n",
            "val_acc 0.8453781604766846\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}